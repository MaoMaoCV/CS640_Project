{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":45867,"databundleVersionId":6924515,"sourceType":"competition"},{"sourceId":7141256,"sourceType":"datasetVersion","datasetId":4093492},{"sourceId":7133331,"sourceType":"datasetVersion","datasetId":4115756}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load CSV files to Pandas DataFrame","metadata":{}},{"cell_type":"markdown","source":"# 1 library","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport math\nimport copy\nimport time\nimport random\nimport glob\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\nimport torchvision\n\n# Utils\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Sklearn Imports\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\n\n# For Image Models\nimport timm\n\n# Albumentations for augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"0,1\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-06T23:36:37.507959Z","iopub.execute_input":"2023-12-06T23:36:37.508232Z","iopub.status.idle":"2023-12-06T23:36:46.015543Z","shell.execute_reply.started":"2023-12-06T23:36:37.508207Z","shell.execute_reply":"2023-12-06T23:36:46.014329Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"train_csv_path = \"/kaggle/input/UBC-OCEAN/train.csv\"\ntest_csv_path = \"/kaggle/input/UBC-OCEAN/test.csv\"\ntrain_pandas_df = pd.read_csv(train_csv_path)\ntest_pandas_df = pd.read_csv(test_csv_path)\nBASE_DIR = [\"/kaggle/input/UBC-OCEAN/train_thumbnails/\", \"/kaggle/input/UBC-OCEAN/test_thumbnails/\"]\n\nclass_distribution = train_pandas_df['label'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.018458Z","iopub.execute_input":"2023-12-06T23:36:46.019268Z","iopub.status.idle":"2023-12-06T23:36:46.058471Z","shell.execute_reply.started":"2023-12-06T23:36:46.019228Z","shell.execute_reply":"2023-12-06T23:36:46.057590Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# 2 Model building","metadata":{}},{"cell_type":"code","source":"\n\nCONFIG = {\n    \"seed\": 42,\n    \"epochs\": 20,\n    \"img_size\": 400,\n    \"model_name\": \"tf_efficientnet_b0_ns\",\n    \"num_classes\": 5,\n    \"train_batch_size\": 32,\n    \"valid_batch_size\": 32,\n    \"learning_rate\": 1e-3,\n    \"scheduler\": 'CosineAnnealingLR',\n    \"min_lr\": 1e-6,\n    \"T_max\": 500,\n    \"weight_decay\": 1e-6,\n    \"fold\" : 0,\n    \"n_fold\": 5,\n    \"n_accumulate\": 1,\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n}\n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.059642Z","iopub.execute_input":"2023-12-06T23:36:46.059988Z","iopub.status.idle":"2023-12-06T23:36:46.136721Z","shell.execute_reply.started":"2023-12-06T23:36:46.059956Z","shell.execute_reply":"2023-12-06T23:36:46.135584Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"'''\nCONFIG = {\n    \"seed\": 42,\n    \"img_size\": 512,\n    \"model_name\": \"tf_efficientnetv2_s_in21ft1k\",# tf_efficientnetv2_s_in21ft1k swin_large_patch4_window12_384\n    \"num_classes\": 5,\n    \"valid_batch_size\": 32,\n    \"scheduler\": 'CosineAnnealingLR',\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n}\n'''\n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.139545Z","iopub.execute_input":"2023-12-06T23:36:46.140420Z","iopub.status.idle":"2023-12-06T23:36:46.148651Z","shell.execute_reply.started":"2023-12-06T23:36:46.140383Z","shell.execute_reply":"2023-12-06T23:36:46.147664Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'\\nCONFIG = {\\n    \"seed\": 42,\\n    \"img_size\": 512,\\n    \"model_name\": \"tf_efficientnetv2_s_in21ft1k\",# tf_efficientnetv2_s_in21ft1k swin_large_patch4_window12_384\\n    \"num_classes\": 5,\\n    \"valid_batch_size\": 32,\\n    \"scheduler\": \\'CosineAnnealingLR\\',\\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\\n}\\n'"},"metadata":{}}]},{"cell_type":"code","source":"def set_seed(seed=42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.149760Z","iopub.execute_input":"2023-12-06T23:36:46.150085Z","iopub.status.idle":"2023-12-06T23:36:46.165505Z","shell.execute_reply.started":"2023-12-06T23:36:46.150061Z","shell.execute_reply":"2023-12-06T23:36:46.164772Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = '/kaggle/input/UBC-OCEAN'\nTRAIN_DIR = '/kaggle/input/UBC-OCEAN/train_thumbnails'\nTEST_DIR = '/kaggle/input/UBC-OCEAN/test_images'\nALT_TEST_DIR = '/kaggle/input/UBC-OCEAN/test_images'","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.166728Z","iopub.execute_input":"2023-12-06T23:36:46.166985Z","iopub.status.idle":"2023-12-06T23:36:46.171377Z","shell.execute_reply.started":"2023-12-06T23:36:46.166963Z","shell.execute_reply":"2023-12-06T23:36:46.170543Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def get_train_file_path(image_id):\n    return f\"{TRAIN_DIR}/{image_id}_thumbnail.png\"\n#    return f\"{TRAIN_DIR}/{image_id}.png\"","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.172342Z","iopub.execute_input":"2023-12-06T23:36:46.172591Z","iopub.status.idle":"2023-12-06T23:36:46.180181Z","shell.execute_reply.started":"2023-12-06T23:36:46.172569Z","shell.execute_reply":"2023-12-06T23:36:46.179148Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_images = sorted(glob.glob(f\"{TRAIN_DIR}/*.png\"))","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.181488Z","iopub.execute_input":"2023-12-06T23:36:46.182101Z","iopub.status.idle":"2023-12-06T23:36:46.239519Z","shell.execute_reply.started":"2023-12-06T23:36:46.182065Z","shell.execute_reply":"2023-12-06T23:36:46.238641Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(f\"{ROOT_DIR}/train.csv\")\ndf['file_path'] = df['image_id'].apply(get_train_file_path)\ndf = df[ df[\"file_path\"].isin(train_images) ].reset_index(drop=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.240656Z","iopub.execute_input":"2023-12-06T23:36:46.240984Z","iopub.status.idle":"2023-12-06T23:36:46.255200Z","shell.execute_reply.started":"2023-12-06T23:36:46.240952Z","shell.execute_reply":"2023-12-06T23:36:46.254475Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ndf['label'] = encoder.fit_transform(df['label'])\n\nwith open(\"label_encoder.pkl\", \"wb\") as fp:\n    joblib.dump(encoder, fp)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.258524Z","iopub.execute_input":"2023-12-06T23:36:46.258817Z","iopub.status.idle":"2023-12-06T23:36:46.266578Z","shell.execute_reply.started":"2023-12-06T23:36:46.258791Z","shell.execute_reply":"2023-12-06T23:36:46.265546Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"CONFIG['T_max'] = df.shape[0] * (CONFIG[\"n_fold\"]-1) * CONFIG['epochs'] // CONFIG['train_batch_size'] // CONFIG[\"n_fold\"]\nCONFIG['T_max']","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.267668Z","iopub.execute_input":"2023-12-06T23:36:46.267961Z","iopub.status.idle":"2023-12-06T23:36:46.276891Z","shell.execute_reply.started":"2023-12-06T23:36:46.267936Z","shell.execute_reply":"2023-12-06T23:36:46.275873Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"256"},"metadata":{}}]},{"cell_type":"markdown","source":"---\n# K-fold\nWith the model defined, let's move on to the Training step.\n\nFor training, I'll use k-fold cross-validation as suggested. During each fold, we'll train the model using the training split and evaluate its performance on the validation split.","metadata":{}},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=CONFIG['n_fold'])\n\nfor fold, ( _, val_) in enumerate(skf.split(X=df, y=df.label)):\n      df.loc[val_ , \"kfold\"] = int(fold)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.277904Z","iopub.execute_input":"2023-12-06T23:36:46.278165Z","iopub.status.idle":"2023-12-06T23:36:46.295812Z","shell.execute_reply.started":"2023-12-06T23:36:46.278135Z","shell.execute_reply":"2023-12-06T23:36:46.295028Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Class","metadata":{}},{"cell_type":"code","source":"class UBCDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.labels = df['label'].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path = self.file_names[index]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        label = self.labels[index]\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n            \n        return {\n            'image': img,\n            'label': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.296754Z","iopub.execute_input":"2023-12-06T23:36:46.297017Z","iopub.status.idle":"2023-12-06T23:36:46.304508Z","shell.execute_reply.started":"2023-12-06T23:36:46.296995Z","shell.execute_reply":"2023-12-06T23:36:46.303643Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentations (transforms)","metadata":{}},{"cell_type":"code","source":"data_transforms = {\n    \"train\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.ShiftScaleRotate(shift_limit=0.1, \n                           scale_limit=0.15, \n                           rotate_limit=60, \n                           p=0.5),\n        A.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=0.5\n            ),\n        A.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5\n            ),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.),\n    \n    \"valid\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.)\n}","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.305758Z","iopub.execute_input":"2023-12-06T23:36:46.306090Z","iopub.status.idle":"2023-12-06T23:36:46.317364Z","shell.execute_reply.started":"2023-12-06T23:36:46.306059Z","shell.execute_reply":"2023-12-06T23:36:46.316564Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# GeM Pooling","metadata":{}},{"cell_type":"code","source":"class GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM, self).__init__()\n        self.p = nn.Parameter(torch.ones(1)*p)\n        self.eps = eps\n\n    def forward(self, x):\n        return self.gem(x, p=self.p, eps=self.eps)\n        \n    def gem(self, x, p=3, eps=1e-6):\n        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n        \n    def __repr__(self):\n        return self.__class__.__name__ + \\\n                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n                ', ' + 'eps=' + str(self.eps) + ')'","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.318559Z","iopub.execute_input":"2023-12-06T23:36:46.318922Z","iopub.status.idle":"2023-12-06T23:36:46.328441Z","shell.execute_reply.started":"2023-12-06T23:36:46.318892Z","shell.execute_reply":"2023-12-06T23:36:46.327415Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Create EfficientNet_b0 Model","metadata":{}},{"cell_type":"code","source":"class UBCModel(nn.Module):\n    def __init__(self, model_name, num_classes, pretrained=True, checkpoint_path=None):\n        super(UBCModel, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n\n        in_features = self.model.classifier.in_features\n        self.model.classifier = nn.Identity()\n        self.model.global_pool = nn.Identity()\n        self.pooling = GeM()\n        self.linear = nn.Linear(in_features, num_classes)\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, images):\n        features = self.model(images)\n        pooled_features = self.pooling(features).flatten(1)\n        output = self.linear(pooled_features)\n        return output\n\n    \n#model = UBCModel(CONFIG['model_name'], CONFIG['num_classes'])#, checkpoint_path=CONFIG['checkpoint_path']\n#model.to(CONFIG['device'])","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.329683Z","iopub.execute_input":"2023-12-06T23:36:46.329941Z","iopub.status.idle":"2023-12-06T23:36:46.341718Z","shell.execute_reply.started":"2023-12-06T23:36:46.329919Z","shell.execute_reply":"2023-12-06T23:36:46.340916Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Loss Function","metadata":{}},{"cell_type":"code","source":"def criterion(outputs, labels):\n    return nn.CrossEntropyLoss()(outputs, labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.342914Z","iopub.execute_input":"2023-12-06T23:36:46.343242Z","iopub.status.idle":"2023-12-06T23:36:46.351728Z","shell.execute_reply.started":"2023-12-06T23:36:46.343211Z","shell.execute_reply":"2023-12-06T23:36:46.350860Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    running_acc  = 0.0\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        images = data['image'].to(device, dtype=torch.float)\n        labels = data['label'].to(device, dtype=torch.long)\n        \n        batch_size = images.size(0)\n        \n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss = loss #/ CONFIG['n_accumulate']\n            \n        loss.backward()\n        \n        \n        optimizer.step()\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        if scheduler is not None:\n            scheduler.step()\n            \n        _, predicted = torch.max(model.softmax(outputs), 1)\n        acc = torch.sum( predicted == labels )\n        \n        running_loss += (loss.item() * batch_size)\n        running_acc  += acc.item()\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        epoch_acc = running_acc / dataset_size\n        \n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, Train_Acc=epoch_acc,\n                        LR=optimizer.param_groups[0]['lr'])\n    gc.collect()\n    \n    return epoch_loss, epoch_acc","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.353143Z","iopub.execute_input":"2023-12-06T23:36:46.353435Z","iopub.status.idle":"2023-12-06T23:36:46.366033Z","shell.execute_reply.started":"2023-12-06T23:36:46.353406Z","shell.execute_reply":"2023-12-06T23:36:46.364864Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"@torch.inference_mode()\ndef valid_one_epoch(model, dataloader, device, epoch):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    running_acc = 0.0\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:        \n        images = data['image'].to(device, dtype=torch.float)\n        labels = data['label'].to(device, dtype=torch.long)\n        \n        batch_size = images.size(0)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        _, predicted = torch.max(model.softmax(outputs), 1)\n        acc = torch.sum( predicted == labels )\n\n        running_loss += (loss.item() * batch_size)\n        running_acc  += acc.item()\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        epoch_acc = running_acc / dataset_size\n        \n        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss, Valid_Acc=epoch_acc,\n                        LR=optimizer.param_groups[0]['lr'])   \n    \n    gc.collect()\n    \n    return epoch_loss, epoch_acc","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.367575Z","iopub.execute_input":"2023-12-06T23:36:46.367932Z","iopub.status.idle":"2023-12-06T23:36:46.381738Z","shell.execute_reply.started":"2023-12-06T23:36:46.367902Z","shell.execute_reply":"2023-12-06T23:36:46.380941Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, device, num_epochs):\n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n    \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_acc = -np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs + 1): \n        gc.collect()\n        train_epoch_loss, train_epoch_acc = train_one_epoch(model, optimizer, scheduler, \n                                           dataloader=train_loader, \n                                           device=CONFIG['device'], epoch=epoch)\n        \n        val_epoch_loss, val_epoch_acc = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n                                         epoch=epoch)\n    \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(val_epoch_loss)\n        history['Train Accuracy'].append(train_epoch_acc)\n        history['Valid Accuracy'].append(val_epoch_acc)\n        history['lr'].append( scheduler.get_lr()[0] )\n        \n        # deep copy the model\n        if best_epoch_acc <= val_epoch_acc:\n            print(f\"{b_}Validation Accuracy Improved ({best_epoch_acc} ---> {val_epoch_acc})\")\n            best_epoch_acc = val_epoch_acc\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = \"Acc{:.2f}_Loss{:.4f}_epoch{:.0f}.bin\".format(best_epoch_acc, val_epoch_loss, epoch)\n            torch.save(model.state_dict(), PATH)\n            # Save a model file from the current directory\n            print(f\"Model Saved{sr_}\")\n            \n        print()\n    \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best Accuracy: {:.4f}\".format(best_epoch_acc))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.383198Z","iopub.execute_input":"2023-12-06T23:36:46.383592Z","iopub.status.idle":"2023-12-06T23:36:46.397556Z","shell.execute_reply.started":"2023-12-06T23:36:46.383561Z","shell.execute_reply":"2023-12-06T23:36:46.396658Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n                                                   eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n                                                             eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == None:\n        return None\n        \n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.398727Z","iopub.execute_input":"2023-12-06T23:36:46.399412Z","iopub.status.idle":"2023-12-06T23:36:46.411055Z","shell.execute_reply.started":"2023-12-06T23:36:46.399380Z","shell.execute_reply":"2023-12-06T23:36:46.410073Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def prepare_loaders(df, fold):\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    train_dataset = UBCDataset(df_train, transforms=data_transforms[\"train\"])\n    valid_dataset = UBCDataset(df_valid, transforms=data_transforms[\"valid\"])\n\n    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n                              num_workers=2, shuffle=False, pin_memory=True)\n    \n    return train_loader, valid_loader","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.414129Z","iopub.execute_input":"2023-12-06T23:36:46.414493Z","iopub.status.idle":"2023-12-06T23:36:46.424282Z","shell.execute_reply.started":"2023-12-06T23:36:46.414459Z","shell.execute_reply":"2023-12-06T23:36:46.423517Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_loader, valid_loader = prepare_loaders(df, fold=CONFIG[\"fold\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.425212Z","iopub.execute_input":"2023-12-06T23:36:46.425472Z","iopub.status.idle":"2023-12-06T23:36:46.439377Z","shell.execute_reply.started":"2023-12-06T23:36:46.425450Z","shell.execute_reply":"2023-12-06T23:36:46.438416Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"'''\nmodel, history = run_training(model, optimizer, scheduler,\n                              device=CONFIG['device'],\n                              num_epochs=CONFIG['epochs'])\n\n'''","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.440491Z","iopub.execute_input":"2023-12-06T23:36:46.440773Z","iopub.status.idle":"2023-12-06T23:36:46.450568Z","shell.execute_reply.started":"2023-12-06T23:36:46.440751Z","shell.execute_reply":"2023-12-06T23:36:46.449396Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"\"\\nmodel, history = run_training(model, optimizer, scheduler,\\n                              device=CONFIG['device'],\\n                              num_epochs=CONFIG['epochs'])\\n\\n\""},"metadata":{}}]},{"cell_type":"code","source":"#torch.save(model.state_dict(),'/kaggle/working/Best_EfficientNet_b2_Model.pth')","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.451809Z","iopub.execute_input":"2023-12-06T23:36:46.452429Z","iopub.status.idle":"2023-12-06T23:36:46.457980Z","shell.execute_reply.started":"2023-12-06T23:36:46.452398Z","shell.execute_reply":"2023-12-06T23:36:46.457220Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#model.load_state_dict(torch.load('/kaggle/input/weight/Best_EfficientNet_b0_Model.pth'))","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.459180Z","iopub.execute_input":"2023-12-06T23:36:46.459514Z","iopub.status.idle":"2023-12-06T23:36:46.466787Z","shell.execute_reply.started":"2023-12-06T23:36:46.459485Z","shell.execute_reply":"2023-12-06T23:36:46.465935Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Loss, Accuracy and Learning Rate","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train 10 models\n'''\nfor i in range(10):\n    \n    model = UBCModel(CONFIG['model_name'], CONFIG['num_classes'])#, checkpoint_path=CONFIG['checkpoint_path']\n    model.to(CONFIG['device'])\n    optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], \n                       weight_decay=CONFIG['weight_decay'])\n    scheduler = fetch_scheduler(optimizer)\n    model, history = run_training(model, optimizer, scheduler,\n                              device=CONFIG['device'],\n                              num_epochs=CONFIG['epochs'])\n    torch.save(model.state_dict(),f\"/kaggle/working/Best_EfficientNet_b0_Model_{i}.pth\")\n'''","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.467799Z","iopub.execute_input":"2023-12-06T23:36:46.468055Z","iopub.status.idle":"2023-12-06T23:36:46.477931Z","shell.execute_reply.started":"2023-12-06T23:36:46.468033Z","shell.execute_reply":"2023-12-06T23:36:46.477083Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'\\nfor i in range(10):\\n    \\n    model = UBCModel(CONFIG[\\'model_name\\'], CONFIG[\\'num_classes\\'])#, checkpoint_path=CONFIG[\\'checkpoint_path\\']\\n    model.to(CONFIG[\\'device\\'])\\n    optimizer = optim.Adam(model.parameters(), lr=CONFIG[\\'learning_rate\\'], \\n                       weight_decay=CONFIG[\\'weight_decay\\'])\\n    scheduler = fetch_scheduler(optimizer)\\n    model, history = run_training(model, optimizer, scheduler,\\n                              device=CONFIG[\\'device\\'],\\n                              num_epochs=CONFIG[\\'epochs\\'])\\n    torch.save(model.state_dict(),f\"/kaggle/working/Best_EfficientNet_b0_Model_{i}.pth\")\\n'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Data","metadata":{}},{"cell_type":"code","source":"# Examine the Data Split of training and testing data\ntrain_data = glob.glob('/kaggle/input/UBC-OCEAN/train_images/*.png')\ntest_data = glob.glob('/kaggle/input/UBC-OCEAN/test_images/*.png')\n\nprint(f\"The Training Set contains: {len(train_data)} images\")\nprint(f\"The Testing Set contains: {len(test_data)} images\")","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.483197Z","iopub.execute_input":"2023-12-06T23:36:46.483471Z","iopub.status.idle":"2023-12-06T23:36:46.523909Z","shell.execute_reply.started":"2023-12-06T23:36:46.483449Z","shell.execute_reply":"2023-12-06T23:36:46.523076Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"The Training Set contains: 538 images\nThe Testing Set contains: 1 images\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_test_file_path(image_id):\n    if os.path.exists(f\"{TEST_DIR}/{image_id}_thumbnail.png\"):\n        return f\"{TEST_DIR}/{image_id}_thumbnail.png\"\n    else:\n        return f\"{ALT_TEST_DIR}/{image_id}.png\"","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.525226Z","iopub.execute_input":"2023-12-06T23:36:46.525560Z","iopub.status.idle":"2023-12-06T23:36:46.530566Z","shell.execute_reply.started":"2023-12-06T23:36:46.525529Z","shell.execute_reply":"2023-12-06T23:36:46.529664Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(f\"{ROOT_DIR}/test.csv\")\ndf_test['file_path'] = df_test['image_id'].apply(get_test_file_path)\ndf_test['label'] = 0 # dummy\ndf_test","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.531725Z","iopub.execute_input":"2023-12-06T23:36:46.532011Z","iopub.status.idle":"2023-12-06T23:36:46.549547Z","shell.execute_reply.started":"2023-12-06T23:36:46.531987Z","shell.execute_reply":"2023-12-06T23:36:46.548704Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"   image_id  image_width  image_height  \\\n0        41        28469         16987   \n\n                                    file_path  label  \n0  /kaggle/input/UBC-OCEAN/test_images/41.png      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>image_width</th>\n      <th>image_height</th>\n      <th>file_path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>28469</td>\n      <td>16987</td>\n      <td>/kaggle/input/UBC-OCEAN/test_images/41.png</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_dataset = UBCDataset(df_test, transforms=data_transforms[\"valid\"])\ntest_loader = DataLoader(test_dataset, batch_size=CONFIG['valid_batch_size'], \n                          num_workers=2, shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.550735Z","iopub.execute_input":"2023-12-06T23:36:46.551331Z","iopub.status.idle":"2023-12-06T23:36:46.558050Z","shell.execute_reply.started":"2023-12-06T23:36:46.551300Z","shell.execute_reply":"2023-12-06T23:36:46.557239Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"df_sub = pd.read_csv(f\"{ROOT_DIR}/sample_submission.csv\")\ndf_sub","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:36:46.559010Z","iopub.execute_input":"2023-12-06T23:36:46.559318Z","iopub.status.idle":"2023-12-06T23:36:46.571559Z","shell.execute_reply.started":"2023-12-06T23:36:46.559287Z","shell.execute_reply":"2023-12-06T23:36:46.570619Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"   image_id label\n0        41  HGSC","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>HGSC</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\nRESULTs=np.array([[]]*len(test_data))\nfor i in range(10):\n    model = UBCModel(CONFIG['model_name'], CONFIG['num_classes'])#, checkpoint_path=CONFIG['checkpoint_path']\n    model.to(CONFIG['device'])\n    model.load_state_dict(torch.load(f'/kaggle/input/weight/Best_EfficientNet_b0_Model_{i}.pth'))\n    preds = []\n    with torch.no_grad():\n        bar = tqdm(enumerate(test_loader), total=len(test_loader))\n        for step, data in bar:        \n            images = data['image'].to(CONFIG[\"device\"], dtype=torch.float)        \n            batch_size = images.size(0)\n            outputs = model(images)\n            _, predicted = torch.max(model.softmax(outputs), 1)\n            preds.append( predicted.detach().cpu().numpy() )\n    preds = np.concatenate(preds).flatten()\n    preds = np.array(preds)\n    preds = preds.reshape(-1,1)\n    RESULTs=np.append(RESULTs,preds,axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:39:06.261702Z","iopub.execute_input":"2023-12-06T23:39:06.262393Z","iopub.status.idle":"2023-12-06T23:39:06.269203Z","shell.execute_reply.started":"2023-12-06T23:39:06.262360Z","shell.execute_reply":"2023-12-06T23:39:06.268156Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'\\nRESULTs=np.array([[]]*len(test_data))\\nfor i in range(10):\\n    model = UBCModel(CONFIG[\\'model_name\\'], CONFIG[\\'num_classes\\'])#, checkpoint_path=CONFIG[\\'checkpoint_path\\']\\n    model.to(CONFIG[\\'device\\'])\\n    model.load_state_dict(torch.load(f\\'/kaggle/input/weight/Best_EfficientNet_b0_Model_{i}.pth\\'))\\n    preds = []\\n    with torch.no_grad():\\n        bar = tqdm(enumerate(test_loader), total=len(test_loader))\\n        for step, data in bar:        \\n            images = data[\\'image\\'].to(CONFIG[\"device\"], dtype=torch.float)        \\n            batch_size = images.size(0)\\n            outputs = model(images)\\n            _, predicted = torch.max(model.softmax(outputs), 1)\\n            preds.append( predicted.detach().cpu().numpy() )\\n    preds = np.concatenate(preds).flatten()\\n    preds = np.array(preds)\\n    preds = preds.reshape(-1,1)\\n    RESULTs=np.append(RESULTs,preds,axis=1)\\n'"},"metadata":{}}]},{"cell_type":"code","source":"RESULTs=RESULTs.astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:37:18.976247Z","iopub.status.idle":"2023-12-06T23:37:18.976953Z","shell.execute_reply.started":"2023-12-06T23:37:18.976708Z","shell.execute_reply":"2023-12-06T23:37:18.976732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RESULT=[]\nfor line in RESULTs:\n    #print(np.argmax(np.bincount(line)))\n    RESULT.append(np.argmax(np.bincount(line)))","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:37:18.978237Z","iopub.status.idle":"2023-12-06T23:37:18.978887Z","shell.execute_reply.started":"2023-12-06T23:37:18.978658Z","shell.execute_reply":"2023-12-06T23:37:18.978681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_labels = encoder.inverse_transform(RESULT)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:37:18.980050Z","iopub.status.idle":"2023-12-06T23:37:18.980807Z","shell.execute_reply.started":"2023-12-06T23:37:18.980521Z","shell.execute_reply":"2023-12-06T23:37:18.980545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub[\"label\"] = pred_labels\ndf_sub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-06T23:37:18.982040Z","iopub.status.idle":"2023-12-06T23:37:18.982729Z","shell.execute_reply.started":"2023-12-06T23:37:18.982488Z","shell.execute_reply":"2023-12-06T23:37:18.982510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}